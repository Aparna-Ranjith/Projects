{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was collected from espncricinfo.com using web scrapping tool- Parsehub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bat=pd.read_csv('batting.csv')\n",
    "#df_bowl=pd.read_csv('bowling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Span</th>\n",
       "      <th>Mat</th>\n",
       "      <th>Inns</th>\n",
       "      <th>NO</th>\n",
       "      <th>Runs</th>\n",
       "      <th>HS</th>\n",
       "      <th>Ave</th>\n",
       "      <th>BF</th>\n",
       "      <th>SR</th>\n",
       "      <th>100s</th>\n",
       "      <th>50s</th>\n",
       "      <th>0s</th>\n",
       "      <th>4s</th>\n",
       "      <th>6s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR Tendulkar (INDIA)</td>\n",
       "      <td>1989-2012</td>\n",
       "      <td>463</td>\n",
       "      <td>452</td>\n",
       "      <td>41</td>\n",
       "      <td>18426</td>\n",
       "      <td>200*</td>\n",
       "      <td>44.83</td>\n",
       "      <td>21368</td>\n",
       "      <td>86.23</td>\n",
       "      <td>49</td>\n",
       "      <td>96</td>\n",
       "      <td>20</td>\n",
       "      <td>2016</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V Kohli (INDIA)</td>\n",
       "      <td>2008-2020</td>\n",
       "      <td>248</td>\n",
       "      <td>239</td>\n",
       "      <td>39</td>\n",
       "      <td>11867</td>\n",
       "      <td>183</td>\n",
       "      <td>59.33</td>\n",
       "      <td>12726</td>\n",
       "      <td>93.25</td>\n",
       "      <td>43</td>\n",
       "      <td>58</td>\n",
       "      <td>13</td>\n",
       "      <td>1116</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT Ponting (AUS/ICC)</td>\n",
       "      <td>1995-2012</td>\n",
       "      <td>375</td>\n",
       "      <td>365</td>\n",
       "      <td>39</td>\n",
       "      <td>13704</td>\n",
       "      <td>164</td>\n",
       "      <td>42.03</td>\n",
       "      <td>17046</td>\n",
       "      <td>80.39</td>\n",
       "      <td>30</td>\n",
       "      <td>82</td>\n",
       "      <td>20</td>\n",
       "      <td>1231</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RG Sharma (INDIA)</td>\n",
       "      <td>2007-2020</td>\n",
       "      <td>224</td>\n",
       "      <td>217</td>\n",
       "      <td>32</td>\n",
       "      <td>9115</td>\n",
       "      <td>264</td>\n",
       "      <td>49.27</td>\n",
       "      <td>10250</td>\n",
       "      <td>88.92</td>\n",
       "      <td>29</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>817</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ST Jayasuriya (Asia/SL)</td>\n",
       "      <td>1989-2011</td>\n",
       "      <td>445</td>\n",
       "      <td>433</td>\n",
       "      <td>18</td>\n",
       "      <td>13430</td>\n",
       "      <td>189</td>\n",
       "      <td>32.36</td>\n",
       "      <td>14725</td>\n",
       "      <td>91.20</td>\n",
       "      <td>28</td>\n",
       "      <td>68</td>\n",
       "      <td>34</td>\n",
       "      <td>1500</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Player       Span  Mat  Inns  NO   Runs    HS    Ave  \\\n",
       "0     SR Tendulkar (INDIA)  1989-2012  463   452  41  18426  200*  44.83   \n",
       "1          V Kohli (INDIA)  2008-2020  248   239  39  11867   183  59.33   \n",
       "2     RT Ponting (AUS/ICC)  1995-2012  375   365  39  13704   164  42.03   \n",
       "3        RG Sharma (INDIA)  2007-2020  224   217  32   9115   264  49.27   \n",
       "4  ST Jayasuriya (Asia/SL)  1989-2011  445   433  18  13430   189  32.36   \n",
       "\n",
       "      BF     SR  100s  50s  0s    4s   6s  \n",
       "0  21368  86.23    49   96  20  2016  195  \n",
       "1  12726  93.25    43   58  13  1116  121  \n",
       "2  17046  80.39    30   82  20  1231  162  \n",
       "3  10250  88.92    29   43  13   817  244  \n",
       "4  14725  91.20    28   68  34  1500  270  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 115 entries, 0 to 114\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Player  115 non-null    object \n",
      " 1   Span    115 non-null    object \n",
      " 2   Mat     115 non-null    int64  \n",
      " 3   Inns    115 non-null    int64  \n",
      " 4   NO      115 non-null    int64  \n",
      " 5   Runs    115 non-null    int64  \n",
      " 6   HS      115 non-null    object \n",
      " 7   Ave     115 non-null    float64\n",
      " 8   BF      115 non-null    int64  \n",
      " 9   SR      115 non-null    float64\n",
      " 10  100s    115 non-null    int64  \n",
      " 11  50s     115 non-null    int64  \n",
      " 12  0s      115 non-null    int64  \n",
      " 13  4s      115 non-null    object \n",
      " 14  6s      115 non-null    object \n",
      "dtypes: float64(2), int64(8), object(5)\n",
      "memory usage: 13.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_bat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing * from Highest score\n",
    "a=[]\n",
    "for i,j in df_bat.iterrows():\n",
    "    a.append(df_bat.iloc[i]['HS'].split('*')[0])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bat['HS']=a\n",
    "df_bat['HS']=df_bat['HS'].astype('int64')\n",
    "# Converting HS from datatype object to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i,j in df_bat.iterrows():\n",
    "    a.append(df_bat.iloc[i]['4s'].split('+')[0])\n",
    "       \n",
    "df_bat['4s']=a\n",
    "df_bat['4s']=df_bat['4s'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i,j in df_bat.iterrows():\n",
    "    a.append(df_bat.iloc[i]['6s'].split('+')[0])\n",
    "       \n",
    "df_bat['6s']=a\n",
    "df_bat['6s']=df_bat['6s'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 115 entries, 0 to 114\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Player  115 non-null    object \n",
      " 1   Span    115 non-null    object \n",
      " 2   Mat     115 non-null    int64  \n",
      " 3   Inns    115 non-null    int64  \n",
      " 4   NO      115 non-null    int64  \n",
      " 5   Runs    115 non-null    int64  \n",
      " 6   HS      115 non-null    int64  \n",
      " 7   Ave     115 non-null    float64\n",
      " 8   BF      115 non-null    int64  \n",
      " 9   SR      115 non-null    float64\n",
      " 10  100s    115 non-null    int64  \n",
      " 11  50s     115 non-null    int64  \n",
      " 12  0s      115 non-null    int64  \n",
      " 13  4s      115 non-null    int64  \n",
      " 14  6s      115 non-null    int64  \n",
      "dtypes: float64(2), int64(11), object(2)\n",
      "memory usage: 13.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_bat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Player    0\n",
       "Span      0\n",
       "Mat       0\n",
       "Inns      0\n",
       "NO        0\n",
       "Runs      0\n",
       "HS        0\n",
       "Ave       0\n",
       "BF        0\n",
       "SR        0\n",
       "100s      0\n",
       "50s       0\n",
       "0s        0\n",
       "4s        0\n",
       "6s        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bat.isnull().sum()   # No null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Derived Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      156.648376\n",
       "1      106.877096\n",
       "2      129.975276\n",
       "3       94.354694\n",
       "4      143.540032\n",
       "          ...    \n",
       "110     80.883922\n",
       "111     78.037936\n",
       "112     82.123782\n",
       "113     87.534112\n",
       "114     93.624466\n",
       "Name: Consistency, Length: 115, dtype: float64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONSISTENCY ------------------------\n",
    "\n",
    "#Consistency = 0.4262*average + 0.2566*no. of innings + 0.1510*SR + 0.0787*Centuries +0.0556*Fifties – 0.0328*Zeros \n",
    "\n",
    "a=[]\n",
    "c=0.0\n",
    "for i,j in df_bat.iterrows():\n",
    "    c= df_bat.iloc[i]['Ave']*0.4262 + 0.2566* df_bat.iloc[i]['Inns']+ 0.1510* df_bat.iloc[i]['SR'] + 0.0787* df_bat.iloc[i]['100s'] + 0.0556* df_bat.iloc[i]['50s'] - 0.0328* df_bat.iloc[i]['0s']\n",
    "    a.append(c)\n",
    "    \n",
    "df_bat['Consistency']=a\n",
    "df_bat['Consistency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORM -------------------------------\n",
    "\n",
    "#Form = 0.4262*average + 0.2566*no. of innings + 0.1510*SR + 0.0787*Centuries +0.0556*Fifties – 0.0328*Zeros \n",
    "\n",
    "a=[]\n",
    "c=0.0\n",
    "for i,j in df_bat.iterrows():\n",
    "    c= df_bat.iloc[i]['Ave']*0.4262 + 0.2566* df_bat.iloc[i]['Inns']+ 0.1510* df_bat.iloc[i]['SR'] + 0.0787* df_bat.iloc[i]['100s'] + 0.0556* df_bat.iloc[i]['50s'] - 0.0328* df_bat.iloc[i]['0s']\n",
    "    a.append(c)\n",
    "    \n",
    "df_bat['Form']=a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPPOSITION ----------------------------\n",
    "\n",
    "#Opposition = 0.4262*average + 0.2566*no. of innings + 0.1510*SR + 0.0787*Centuries +0.0556*Fifties – 0.0328*Zeros \n",
    "\n",
    "a=[]\n",
    "c=0.0\n",
    "for i,j in df_bat.iterrows():\n",
    "    c= df_bat.iloc[i]['Ave']*0.4262 + 0.2566* df_bat.iloc[i]['Inns']+ 0.1510* df_bat.iloc[i]['SR'] + 0.0787* df_bat.iloc[i]['100s'] + 0.0556* df_bat.iloc[i]['50s'] - 0.0328* df_bat.iloc[i]['0s']\n",
    "    a.append(c)\n",
    "    \n",
    "df_bat['Opposition']=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      156.648376\n",
       "1      106.877096\n",
       "2      129.975276\n",
       "3       94.354694\n",
       "4      143.540032\n",
       "          ...    \n",
       "110     80.883922\n",
       "111     78.037936\n",
       "112     82.123782\n",
       "113     87.534112\n",
       "114     93.624466\n",
       "Name: Venue, Length: 115, dtype: float64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VENUE -------------------------\n",
    "\n",
    "#Venue = 0.4262*average + 0.2566*no. of innings + 0.1510*SR + 0.0787*Centuries +0.0556*Fifties – 0.0328*Zeros\n",
    "\n",
    "a=[]\n",
    "c=0.0\n",
    "for i,j in df_bat.iterrows():\n",
    "    c= df_bat.iloc[i]['Ave']*0.4262 + 0.2566* df_bat.iloc[i]['Inns']+ 0.1510* df_bat.iloc[i]['SR'] + 0.0787* df_bat.iloc[i]['100s'] + 0.0556* df_bat.iloc[i]['50s'] - 0.0328* df_bat.iloc[i]['0s']\n",
    "    a.append(c)\n",
    "    \n",
    "df_bat['Venue']=a\n",
    "\n",
    "df_bat['Venue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alert!!! ----- The paper has presented same formula for all four derived attributes Consistency, Form, Opposition ad Venue. This is an error in the paper. \n",
    "### For the same reason, here Consistency is the only attribute being considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping other three derived attributes\n",
    "df_bat.drop(columns=['Form','Opposition','Venue'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Player', 'Span', 'Mat', 'Inns', 'NO', 'Runs', 'HS', 'Ave', 'BF', 'SR',\n",
       "       '100s', '50s', '0s', '4s', '6s', 'Consistency'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bat.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Class - Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i,j in df_bat.iterrows():\n",
    "    if((df_bat.iloc[i]['Consistency']>=1)&(df_bat.iloc[i]['Consistency']<=49)):\n",
    "        r=1\n",
    "    elif((df_bat.iloc[i]['Consistency']>=50)&(df_bat.iloc[i]['Consistency']<=99)):\n",
    "        r=2\n",
    "    elif((df_bat.iloc[i]['Consistency']>=100)&(df_bat.iloc[i]['Consistency']<=124)):\n",
    "        r=3\n",
    "    elif((df_bat.iloc[i]['Consistency']>=125)&(df_bat.iloc[i]['Consistency']<=149)):\n",
    "        r=4\n",
    "    elif(df_bat.iloc[i]['Consistency']>=150):\n",
    "        r=5 \n",
    "    a.append(r)\n",
    "    \n",
    "df_bat['Rating']=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5\n",
       "1      3\n",
       "2      4\n",
       "3      2\n",
       "4      4\n",
       "      ..\n",
       "110    2\n",
       "111    2\n",
       "112    2\n",
       "113    2\n",
       "114    2\n",
       "Name: Rating, Length: 115, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bat['Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_bat.iloc[:,:-1]  # All columns except Rating\n",
    "y=df_bat.iloc[:,-1]  # Rating as the target class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=['Player','Span'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Mat', 'Inns', 'NO', 'Runs', 'HS', 'Ave', 'BF', 'SR', '100s', '50s',\n",
       "       '0s', '4s', '6s', 'Consistency'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into Train and Test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "X_train_scaled=zscore(X_train)\n",
    "X_test_scaled=zscore(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "\n",
    "nb.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9456521739130435\n",
      "Test score:  0.8695652173913043\n"
     ]
    }
   ],
   "source": [
    "nbtrain=nb.score(X_train_scaled,y_train)\n",
    "nbtest=nb.score(X_test_scaled,y_test)\n",
    "\n",
    "print('Train score: ', nbtrain)\n",
    "print('Test score: ', nbtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted=nb.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      1.00      0.80         2\n",
      "           2       1.00      0.81      0.90        16\n",
      "           3       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.87        23\n",
      "   macro avg       0.79      0.94      0.84        23\n",
      "weighted avg       0.91      0.87      0.87        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=9, splitter='best')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt=DecisionTreeClassifier(max_depth=4,random_state=9)\n",
    "dt.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  1.0\n",
      "Test score:  0.9130434782608695\n"
     ]
    }
   ],
   "source": [
    "dttrain=dt.score(X_train_scaled,y_train)\n",
    "dttest=dt.score(X_test_scaled,y_test)\n",
    "\n",
    "print('Train score: ', dttrain)\n",
    "print('Test score: ', dttest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.50      0.67         2\n",
      "           2       0.94      0.94      0.94        16\n",
      "           3       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.91        23\n",
      "   macro avg       0.92      0.81      0.84        23\n",
      "weighted avg       0.92      0.91      0.91        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted=dt.predict(X_test_scaled)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=3, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=10, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(max_depth=3,random_state=10)\n",
    "rf.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9891304347826086\n",
      "Test score:  0.9565217391304348\n"
     ]
    }
   ],
   "source": [
    "rftrain=rf.score(X_train_scaled,y_train)\n",
    "rftest=rf.score(X_test_scaled,y_test)\n",
    "\n",
    "print('Train score: ', rftrain)\n",
    "print('Test score: ', rftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      1.00      0.80         2\n",
      "           2       1.00      0.94      0.97        16\n",
      "           3       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.96        23\n",
      "   macro avg       0.89      0.98      0.92        23\n",
      "weighted avg       0.97      0.96      0.96        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted=rf.predict(X_test_scaled)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC()\n",
    "svc.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9239130434782609\n",
      "Test score:  0.8695652173913043\n"
     ]
    }
   ],
   "source": [
    "svctrain=svc.score(X_train_scaled,y_train)\n",
    "svctest=svc.score(X_test_scaled,y_test)\n",
    "\n",
    "print('Train score: ', svctrain)\n",
    "print('Test score: ', svctest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.88      0.94      0.91        16\n",
      "           3       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.87        23\n",
      "   macro avg       0.57      0.65      0.61        23\n",
      "weighted avg       0.79      0.87      0.83        23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_predicted=svc.predict(X_test_scaled)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame(index=['Naive Bayes','Decision Tree','Random Forest','SVM'],columns=['Train acuuracy%', 'Test Accuracy%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.iloc[0,0]=nbtrain\n",
    "results.iloc[0,1]=nbtest\n",
    "results.iloc[1,0]=dttrain\n",
    "results.iloc[1,1]=dttest\n",
    "results.iloc[2,0]=rftrain\n",
    "results.iloc[2,1]=rftest\n",
    "results.iloc[3,0]=svctrain\n",
    "results.iloc[3,1]=svctest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train acuuracy%</th>\n",
       "      <th>Test Accuracy%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>1</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.98913</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Train acuuracy% Test Accuracy%\n",
       "Naive Bayes          0.945652       0.869565\n",
       "Decision Tree               1       0.913043\n",
       "Random Forest         0.98913       0.956522\n",
       "SVM                  0.923913       0.869565"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest has shown the best performance on a split of train data 80% and test data 20%. \n",
    "This result is in tally with the results presented in the reserach paper."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
