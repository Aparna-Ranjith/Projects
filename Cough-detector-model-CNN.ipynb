{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, MaxPooling2D, Input\n",
    "from keras.layers.core import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras import metrics, optimizers\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import librosa.display\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresdf=pd.read_pickle('featuresdf_5.pkl')  #contains mfcc features of all samples and corresponding class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-629.0347579657414, -629.0347579657414, -629...</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-165.33815931479825, -173.28544807355715, -1...</td>\n",
       "      <td>chirping_birds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-446.0381550382831, -444.05035045796683, -44...</td>\n",
       "      <td>thunderstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-462.8407001928654, -463.01179671431885, -46...</td>\n",
       "      <td>thunderstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-484.0664969477341, -487.5931492300499, -349...</td>\n",
       "      <td>door_wood_knock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature      class_label\n",
       "0  [[-629.0347579657414, -629.0347579657414, -629...              dog\n",
       "1  [[-165.33815931479825, -173.28544807355715, -1...   chirping_birds\n",
       "2  [[-446.0381550382831, -444.05035045796683, -44...     thunderstorm\n",
       "3  [[-462.8407001928654, -463.01179671431885, -46...     thunderstorm\n",
       "4  [[-484.0664969477341, -487.5931492300499, -349...  door_wood_knock"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "num_rows = 40\n",
    "num_columns = 216\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "\n",
    "# Construct model BOAW\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aparna\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1832 samples, validate on 459 samples\n",
      "Epoch 1/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 4.4464 - accuracy: 0.1376 - val_loss: 2.8234 - val_accuracy: 0.1830\n",
      "Epoch 2/100\n",
      "1832/1832 [==============================] - 8s 4ms/step - loss: 2.4525 - accuracy: 0.2598 - val_loss: 2.4125 - val_accuracy: 0.3900\n",
      "Epoch 3/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 2.0854 - accuracy: 0.3455 - val_loss: 2.0942 - val_accuracy: 0.4227\n",
      "Epoch 4/100\n",
      "1832/1832 [==============================] - 8s 4ms/step - loss: 1.8715 - accuracy: 0.4099 - val_loss: 1.9185 - val_accuracy: 0.4749\n",
      "Epoch 5/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 1.7623 - accuracy: 0.4487 - val_loss: 1.8040 - val_accuracy: 0.4924\n",
      "Epoch 6/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 1.5426 - accuracy: 0.4951 - val_loss: 1.6858 - val_accuracy: 0.5185\n",
      "Epoch 7/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 1.4807 - accuracy: 0.5142 - val_loss: 1.5612 - val_accuracy: 0.5730\n",
      "Epoch 8/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 1.3925 - accuracy: 0.5459 - val_loss: 1.4367 - val_accuracy: 0.5948\n",
      "Epoch 9/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 1.2830 - accuracy: 0.5830 - val_loss: 1.4691 - val_accuracy: 0.5839\n",
      "Epoch 10/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 1.1862 - accuracy: 0.6201 - val_loss: 1.3363 - val_accuracy: 0.6253\n",
      "Epoch 11/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 1.1275 - accuracy: 0.6223 - val_loss: 1.2663 - val_accuracy: 0.6449\n",
      "Epoch 12/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 1.0432 - accuracy: 0.6517 - val_loss: 1.2490 - val_accuracy: 0.6492\n",
      "Epoch 13/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 0.9975 - accuracy: 0.6627 - val_loss: 1.0836 - val_accuracy: 0.7081\n",
      "Epoch 14/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.9504 - accuracy: 0.6769 - val_loss: 1.0982 - val_accuracy: 0.7037\n",
      "Epoch 15/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 0.8870 - accuracy: 0.6998 - val_loss: 1.0484 - val_accuracy: 0.6841\n",
      "Epoch 16/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.8479 - accuracy: 0.7172 - val_loss: 1.0187 - val_accuracy: 0.7124\n",
      "Epoch 17/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 0.8639 - accuracy: 0.7189 - val_loss: 1.0092 - val_accuracy: 0.7037\n",
      "Epoch 18/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.7471 - accuracy: 0.7527 - val_loss: 0.9911 - val_accuracy: 0.7124\n",
      "Epoch 19/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.7270 - accuracy: 0.7576 - val_loss: 0.9507 - val_accuracy: 0.7211\n",
      "Epoch 20/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.6780 - accuracy: 0.7647 - val_loss: 0.9422 - val_accuracy: 0.7081\n",
      "Epoch 21/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.6261 - accuracy: 0.7904 - val_loss: 0.8926 - val_accuracy: 0.7255\n",
      "Epoch 22/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.6354 - accuracy: 0.7871 - val_loss: 0.8311 - val_accuracy: 0.7691\n",
      "Epoch 23/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.5763 - accuracy: 0.8160 - val_loss: 0.8066 - val_accuracy: 0.7691\n",
      "Epoch 24/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.5315 - accuracy: 0.8226 - val_loss: 0.7658 - val_accuracy: 0.7582\n",
      "Epoch 25/100\n",
      "1832/1832 [==============================] - 10s 5ms/step - loss: 0.5428 - accuracy: 0.8139 - val_loss: 0.9950 - val_accuracy: 0.6906\n",
      "Epoch 26/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.5281 - accuracy: 0.8264 - val_loss: 0.7516 - val_accuracy: 0.7843\n",
      "Epoch 27/100\n",
      "1832/1832 [==============================] - 10s 5ms/step - loss: 0.4547 - accuracy: 0.8444 - val_loss: 0.7832 - val_accuracy: 0.7603\n",
      "Epoch 28/100\n",
      "1832/1832 [==============================] - 11s 6ms/step - loss: 0.4499 - accuracy: 0.8428 - val_loss: 0.7648 - val_accuracy: 0.7516\n",
      "Epoch 29/100\n",
      "1832/1832 [==============================] - 10s 5ms/step - loss: 0.4345 - accuracy: 0.8575 - val_loss: 0.8282 - val_accuracy: 0.7451\n",
      "Epoch 30/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.4702 - accuracy: 0.8412 - val_loss: 0.6880 - val_accuracy: 0.8061\n",
      "Epoch 31/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.4000 - accuracy: 0.8652 - val_loss: 0.7709 - val_accuracy: 0.7560\n",
      "Epoch 32/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.3580 - accuracy: 0.8783 - val_loss: 0.8740 - val_accuracy: 0.7386\n",
      "Epoch 33/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.3729 - accuracy: 0.8739 - val_loss: 0.6585 - val_accuracy: 0.8039\n",
      "Epoch 34/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.3663 - accuracy: 0.8745 - val_loss: 0.6240 - val_accuracy: 0.8214\n",
      "Epoch 35/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.3580 - accuracy: 0.8772 - val_loss: 0.6673 - val_accuracy: 0.7908\n",
      "Epoch 36/100\n",
      "1832/1832 [==============================] - 8s 4ms/step - loss: 0.3271 - accuracy: 0.8859 - val_loss: 0.6615 - val_accuracy: 0.8083\n",
      "Epoch 37/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.3191 - accuracy: 0.8886 - val_loss: 0.6111 - val_accuracy: 0.8105\n",
      "Epoch 38/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.2642 - accuracy: 0.9110 - val_loss: 0.6881 - val_accuracy: 0.8126\n",
      "Epoch 39/100\n",
      "1832/1832 [==============================] - 10s 6ms/step - loss: 0.3136 - accuracy: 0.8947 - val_loss: 0.7159 - val_accuracy: 0.7908\n",
      "Epoch 40/100\n",
      "1832/1832 [==============================] - 10s 5ms/step - loss: 0.2687 - accuracy: 0.9088 - val_loss: 0.6514 - val_accuracy: 0.7908\n",
      "Epoch 41/100\n",
      "1832/1832 [==============================] - 10s 5ms/step - loss: 0.2559 - accuracy: 0.9203 - val_loss: 0.6398 - val_accuracy: 0.8061\n",
      "Epoch 42/100\n",
      "1832/1832 [==============================] - 11s 6ms/step - loss: 0.3012 - accuracy: 0.9067 - val_loss: 0.6646 - val_accuracy: 0.7996\n",
      "Epoch 43/100\n",
      "1832/1832 [==============================] - 10s 6ms/step - loss: 0.2565 - accuracy: 0.9138 - val_loss: 0.5373 - val_accuracy: 0.8366\n",
      "Epoch 44/100\n",
      "1832/1832 [==============================] - 10s 5ms/step - loss: 0.2589 - accuracy: 0.9143 - val_loss: 0.6859 - val_accuracy: 0.8170\n",
      "Epoch 45/100\n",
      "1832/1832 [==============================] - 10s 6ms/step - loss: 0.2702 - accuracy: 0.8990 - val_loss: 0.6130 - val_accuracy: 0.8148\n",
      "Epoch 46/100\n",
      "1832/1832 [==============================] - 11s 6ms/step - loss: 0.2889 - accuracy: 0.8968 - val_loss: 0.7164 - val_accuracy: 0.7865\n",
      "Epoch 47/100\n",
      "1832/1832 [==============================] - 13s 7ms/step - loss: 0.2531 - accuracy: 0.9148 - val_loss: 0.4846 - val_accuracy: 0.8671\n",
      "Epoch 48/100\n",
      "1832/1832 [==============================] - 11s 6ms/step - loss: 0.2151 - accuracy: 0.9350 - val_loss: 0.5394 - val_accuracy: 0.8540\n",
      "Epoch 49/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.2035 - accuracy: 0.9329 - val_loss: 0.6024 - val_accuracy: 0.8431\n",
      "Epoch 50/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1902 - accuracy: 0.9410 - val_loss: 0.5208 - val_accuracy: 0.8453\n",
      "Epoch 51/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1961 - accuracy: 0.9361 - val_loss: 0.5197 - val_accuracy: 0.8649\n",
      "Epoch 52/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1791 - accuracy: 0.9378 - val_loss: 0.5850 - val_accuracy: 0.8366\n",
      "Epoch 53/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.2144 - accuracy: 0.9236 - val_loss: 0.5763 - val_accuracy: 0.8519\n",
      "Epoch 54/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 0.1670 - accuracy: 0.9438 - val_loss: 0.5628 - val_accuracy: 0.8540\n",
      "Epoch 55/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1879 - accuracy: 0.9410 - val_loss: 0.6676 - val_accuracy: 0.8344\n",
      "Epoch 56/100\n",
      "1832/1832 [==============================] - 8s 4ms/step - loss: 0.1806 - accuracy: 0.9460 - val_loss: 0.5385 - val_accuracy: 0.8627\n",
      "Epoch 57/100\n",
      "1832/1832 [==============================] - 8s 4ms/step - loss: 0.1650 - accuracy: 0.9460 - val_loss: 0.5946 - val_accuracy: 0.8235\n",
      "Epoch 58/100\n",
      "1832/1832 [==============================] - 8s 4ms/step - loss: 0.1902 - accuracy: 0.9356 - val_loss: 0.5867 - val_accuracy: 0.8453\n",
      "Epoch 59/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 0.1875 - accuracy: 0.9329 - val_loss: 0.6796 - val_accuracy: 0.8279\n",
      "Epoch 60/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 0.1759 - accuracy: 0.9389 - val_loss: 0.6180 - val_accuracy: 0.8562\n",
      "Epoch 61/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1785 - accuracy: 0.9460 - val_loss: 0.4961 - val_accuracy: 0.8758\n",
      "Epoch 62/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1381 - accuracy: 0.9580 - val_loss: 0.4873 - val_accuracy: 0.8584\n",
      "Epoch 63/100\n",
      "1832/1832 [==============================] - 10s 5ms/step - loss: 0.1354 - accuracy: 0.9591 - val_loss: 0.5458 - val_accuracy: 0.8562\n",
      "Epoch 64/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1202 - accuracy: 0.9602 - val_loss: 0.5119 - val_accuracy: 0.8671\n",
      "Epoch 65/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1388 - accuracy: 0.9531 - val_loss: 0.5598 - val_accuracy: 0.8562\n",
      "Epoch 66/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1547 - accuracy: 0.9487 - val_loss: 0.5332 - val_accuracy: 0.8671\n",
      "Epoch 67/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1635 - accuracy: 0.9471 - val_loss: 0.4537 - val_accuracy: 0.8780\n",
      "Epoch 68/100\n",
      "1832/1832 [==============================] - 10s 6ms/step - loss: 0.1261 - accuracy: 0.9645 - val_loss: 0.6340 - val_accuracy: 0.8497\n",
      "Epoch 69/100\n",
      "1832/1832 [==============================] - 10s 5ms/step - loss: 0.1476 - accuracy: 0.9525 - val_loss: 0.5713 - val_accuracy: 0.8453\n",
      "Epoch 70/100\n",
      "1832/1832 [==============================] - 10s 5ms/step - loss: 0.1160 - accuracy: 0.9629 - val_loss: 0.5242 - val_accuracy: 0.8780\n",
      "Epoch 71/100\n",
      "1832/1832 [==============================] - 10s 6ms/step - loss: 0.1113 - accuracy: 0.9634 - val_loss: 0.5177 - val_accuracy: 0.8671\n",
      "Epoch 72/100\n",
      "1832/1832 [==============================] - 10s 5ms/step - loss: 0.0952 - accuracy: 0.9678 - val_loss: 0.4839 - val_accuracy: 0.8802\n",
      "Epoch 73/100\n",
      "1832/1832 [==============================] - 10s 6ms/step - loss: 0.1219 - accuracy: 0.9607 - val_loss: 0.5188 - val_accuracy: 0.8845\n",
      "Epoch 74/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1302 - accuracy: 0.9558 - val_loss: 0.4748 - val_accuracy: 0.8715\n",
      "Epoch 75/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1118 - accuracy: 0.9667 - val_loss: 0.5029 - val_accuracy: 0.8736\n",
      "Epoch 76/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 0.0973 - accuracy: 0.9683 - val_loss: 0.5959 - val_accuracy: 0.8453\n",
      "Epoch 77/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1667 - accuracy: 0.9509 - val_loss: 0.5018 - val_accuracy: 0.8497\n",
      "Epoch 78/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1559 - accuracy: 0.9531 - val_loss: 0.4966 - val_accuracy: 0.8758\n",
      "Epoch 79/100\n",
      "1832/1832 [==============================] - 8s 4ms/step - loss: 0.1260 - accuracy: 0.9569 - val_loss: 0.4837 - val_accuracy: 0.8802\n",
      "Epoch 80/100\n",
      "1832/1832 [==============================] - 10s 6ms/step - loss: 0.1246 - accuracy: 0.9552 - val_loss: 0.3899 - val_accuracy: 0.9063\n",
      "Epoch 81/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.0850 - accuracy: 0.9722 - val_loss: 0.4123 - val_accuracy: 0.9150\n",
      "Epoch 82/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 0.1124 - accuracy: 0.9656 - val_loss: 0.4388 - val_accuracy: 0.8954\n",
      "Epoch 83/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 0.0987 - accuracy: 0.9634 - val_loss: 0.4197 - val_accuracy: 0.8845\n",
      "Epoch 84/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 0.1002 - accuracy: 0.9651 - val_loss: 0.4636 - val_accuracy: 0.8889\n",
      "Epoch 85/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.0954 - accuracy: 0.9662 - val_loss: 0.6503 - val_accuracy: 0.8519\n",
      "Epoch 86/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.0873 - accuracy: 0.9683 - val_loss: 0.4938 - val_accuracy: 0.8932\n",
      "Epoch 87/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.0869 - accuracy: 0.9733 - val_loss: 0.5069 - val_accuracy: 0.8845\n",
      "Epoch 88/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 0.0704 - accuracy: 0.9787 - val_loss: 0.5096 - val_accuracy: 0.8845\n",
      "Epoch 89/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1098 - accuracy: 0.9612 - val_loss: 0.5308 - val_accuracy: 0.8693\n",
      "Epoch 90/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 0.0713 - accuracy: 0.9733 - val_loss: 0.4228 - val_accuracy: 0.8889\n",
      "Epoch 91/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.0694 - accuracy: 0.9765 - val_loss: 0.4757 - val_accuracy: 0.8954\n",
      "Epoch 92/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.0943 - accuracy: 0.9694 - val_loss: 0.5438 - val_accuracy: 0.8845\n",
      "Epoch 93/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.0861 - accuracy: 0.9705 - val_loss: 0.5217 - val_accuracy: 0.8867\n",
      "Epoch 94/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.0640 - accuracy: 0.9787 - val_loss: 0.5098 - val_accuracy: 0.8932\n",
      "Epoch 95/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.0720 - accuracy: 0.9782 - val_loss: 0.4980 - val_accuracy: 0.8932\n",
      "Epoch 96/100\n",
      "1832/1832 [==============================] - 10s 5ms/step - loss: 0.0817 - accuracy: 0.9716 - val_loss: 0.6198 - val_accuracy: 0.8606\n",
      "Epoch 97/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1011 - accuracy: 0.9683 - val_loss: 0.5060 - val_accuracy: 0.8802\n",
      "Epoch 98/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.0705 - accuracy: 0.9771 - val_loss: 0.5510 - val_accuracy: 0.8802\n",
      "Epoch 99/100\n",
      "1832/1832 [==============================] - 8s 5ms/step - loss: 0.0966 - accuracy: 0.9656 - val_loss: 0.5520 - val_accuracy: 0.8845\n",
      "Epoch 100/100\n",
      "1832/1832 [==============================] - 9s 5ms/step - loss: 0.1012 - accuracy: 0.9694 - val_loss: 0.5472 - val_accuracy: 0.8715\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 40\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./weights.best.basic_mlp.hdf5', verbose=1, save_best_only=True)\n",
    "# start = datetime.now()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9890829920768738\n",
      "Testing Accuracy:  0.8714597225189209\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_features(file_name) \n",
    "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "  audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "  mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "  mfccs = mfccs[:40,:216]\n",
    "  #mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "     \n",
    "  return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording\n",
      "Finished recording\n",
      "The predicted class is: coughing \n",
      "\n",
      "airplane \t\t :  0.00000000000868114087559934688443\n",
      "breathing \t\t :  0.00000001328919019272234436357394\n",
      "car_horn \t\t :  0.00000939905839913990348577499390\n",
      "cat \t\t :  0.00756435375660657882690429687500\n",
      "chainsaw \t\t :  0.00000232847673942160326987504959\n",
      "chirping_birds \t\t :  0.00000000094574559295068638675730\n",
      "church_bells \t\t :  0.00000005796879065655957674607635\n",
      "clapping \t\t :  0.00046498881420120596885681152344\n",
      "clock_alarm \t\t :  0.00000000009123027333579614150949\n",
      "coughing \t\t :  0.98489040136337280273437500000000\n",
      "cow \t\t :  0.00002293525903951376676559448242\n",
      "crow \t\t :  0.00006286464486038312315940856934\n",
      "crying_baby \t\t :  0.00060460029635578393936157226562\n",
      "dog \t\t :  0.00000065688846007105894386768341\n",
      "door_wood_knock \t\t :  0.00000000010331457217516160085324\n",
      "engine \t\t :  0.00000000556923263062003570667002\n",
      "fireworks \t\t :  0.00000000000632478401249580990395\n",
      "helicopter \t\t :  0.00000000000003498534402175505764\n",
      "laughing \t\t :  0.00055768043966963887214660644531\n",
      "rain \t\t :  0.00000000000818231853799700203922\n",
      "siren \t\t :  0.00000000002402029096459923351858\n",
      "speech \t\t :  0.00581966852769255638122558593750\n",
      "thunderstorm \t\t :  0.00000000017946302777183120724658\n",
      "train \t\t :  0.00000000000007391973860272627039\n",
      "wind \t\t :  0.00000000000128083231954595477831\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "chunk = 1024  # Record in chunks of 1024 samples\n",
    "sample_format = pyaudio.paInt32  # 16 bits per sample\n",
    "channels = 1\n",
    "fs = 44100  # Record at 44100 samples per second\n",
    "seconds = 5\n",
    "filename = \"/Users/Aparna/Desktop/output.wav\"\n",
    "for i in range(1,2):\n",
    "    p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "    print('Recording')\n",
    "    stream = p.open(format=sample_format, channels=channels, rate=fs, frames_per_buffer=chunk, input=True)\n",
    "    frames = []  # Initialize array to store frames\n",
    "    # Store data in chunks for 5 seconds\n",
    "    for i in range(0, int(fs / chunk * seconds)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "    # Stop and close the stream \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    # Terminate the PortAudio interface\n",
    "    p.terminate()\n",
    "    print('Finished recording')\n",
    "    # Save the recorded data as a WAV file\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "    wf.setframerate(fs)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    print_prediction(filename)\n",
    "    # predictSound(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
